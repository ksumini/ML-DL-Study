{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "angry-handbook",
   "metadata": {},
   "source": [
    "# 프로젝트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alert-jewelry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['[Hook]', \"I've been down so long, it look like up to me\", 'They look up to me']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-liberal",
   "metadata": {},
   "source": [
    "## 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "critical-wildlife",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n",
      "<start> thissentence . <end>\n",
      "<start> i eat lunch <end>\n"
     ]
    }
   ],
   "source": [
    "# 입력된 문장을\n",
    "#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
    "#     2. 특수문자 양쪽에 공백을 넣고\n",
    "#     3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
    "#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
    "#     5. 다시 양쪽 공백을 지웁니다\n",
    "#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
    "# 이 순서로 처리해주면 문제가 되는 상황을 방지할 수 있겠네요!\n",
    "import re\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
    "    return sentence\n",
    "\n",
    "# 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))\n",
    "print(preprocess_sentence(\"Thissentence.\"))\n",
    "print(preprocess_sentence(\"I eat lunch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "opened-antigua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> hook <end>',\n",
       " '<start> i ve been down so long , it look like up to me <end>',\n",
       " '<start> they look up to me <end>',\n",
       " '<start> i got fake people showin fake love to me <end>',\n",
       " '<start> straight up to my face , straight up to my face <end>',\n",
       " '<start> i ve been down so long , it look like up to me <end>',\n",
       " '<start> they look up to me <end>',\n",
       " '<start> i got fake people showin fake love to me <end>',\n",
       " '<start> somethin ain t right when we talkin <end>',\n",
       " '<start> somethin ain t right when we talkin <end>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue # 길이가 0인 문장은 건너뜁니다\n",
    "    if len(sentence) > 50: continue\n",
    "    if sentence[-1] == \":\": continue # 문장의 끝이 :인 문장은 건너뜁니다\n",
    "        \n",
    "    corpus.append(preprocess_sentence(sentence))\n",
    "        \n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-hopkins",
   "metadata": {},
   "source": [
    "## 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dried-upset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2  941    3 ...    0    0    0]\n",
      " [   2    4   94 ...   10   12    3]\n",
      " [   2   46  134 ...    0    0    0]\n",
      " ...\n",
      " [   2  198    3 ...    0    0    0]\n",
      " [   2  442    9 ...    0    0    0]\n",
      " [   2    9 1610 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f086990a390>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "def tokenize(corpus):\n",
    "    # 텐서플로우에서 제공하는 Tokenizer 패키지를 생성\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000,  # 전체 단어의 개수 \n",
    "        filters=' ',    # 별도로 전처리 로직을 추가할 수 있습니다. 이번에는 사용하지 않겠습니다.\n",
    "        oov_token=\"<unk>\"  # out-of-vocabulary, 사전에 없었던 단어는 어떤 토큰으로 대체할지\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)   # 우리가 구축한 corpus로부터 Tokenizer가 사전을 자동구축하게 됩니다.\n",
    "\n",
    "    # 이후 tokenizer를 활용하여 모델에 입력할 데이터셋을 구축하게 됩니다.\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   # tokenizer는 구축한 사전으로부터 corpus를 해석해 Tensor로 변환합니다.\n",
    "\n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞추기 위한 padding  메소드를 제공합니다.\n",
    "    # maxlen의 디폴트값은 None입니다. 이 경우 corpus의 가장 긴 문장을 기준으로 시퀀스 길이가 맞춰집니다.\n",
    "    # maxlen=15를 설정해서 토큰의 개수가 15개를 최대로 설정, 15개 초과하는 데이터는 제외\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15)\n",
    "\n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "double-conditioning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2 941   3   0   0   0   0   0   0   0   0   0   0   0]\n",
      "[941   3   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "142443\n",
      "142443\n"
     ]
    }
   ],
   "source": [
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
    "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "src_input = tensor[:, :-1]  \n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])\n",
    "print(len(src_input))\n",
    "print(len(tgt_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-vulnerability",
   "metadata": {},
   "source": [
    "## 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "certified-shower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (113954, 14)\n",
      "Target Train: (113954, 14)\n"
     ]
    }
   ],
   "source": [
    "# train, test 분리\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input,\n",
    "                                                          tgt_input,\n",
    "                                                          test_size=0.2,\n",
    "                                                          shuffle=True)\n",
    "\n",
    "print(\"Source Train:\", enc_train.shape) # 소스 문장\n",
    "print(\"Target Train:\", dec_train.shape) # 타겟 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "collect-defendant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>\n",
      "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n",
    "# 데이터셋에 대해서는 아래 문서를 참고하세요\n",
    "# 자세히 알아둘수록 도움이 많이 되는 중요한 문서입니다\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "dataset1 = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE)\n",
    "dataset1 = dataset1.batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset1)\n",
    "\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices((enc_val, dec_val)).shuffle(BUFFER_SIZE)\n",
    "dataset2 = dataset2.batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sorted-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "monetary-investigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-6.21630315e-05  5.10329774e-05 -2.28092013e-05 ...  1.07920874e-04\n",
      "    1.30119706e-05 -1.97675195e-06]\n",
      "  [-2.76733736e-05  3.83767110e-06 -6.26690598e-05 ...  1.37086274e-04\n",
      "    4.02425685e-05  7.19083546e-05]\n",
      "  [-2.38473993e-04  3.72791510e-06  3.47908463e-06 ...  2.20556947e-04\n",
      "    1.78690985e-04  8.85536356e-05]\n",
      "  ...\n",
      "  [-6.23432163e-04 -2.02017813e-03  1.20721222e-03 ...  3.18764505e-04\n",
      "    1.48974895e-03 -8.22309579e-04]\n",
      "  [-8.48433876e-04 -2.15080590e-03  1.44522812e-03 ...  1.01578080e-04\n",
      "    1.70652894e-03 -9.18670266e-04]\n",
      "  [-1.05173502e-03 -2.24655494e-03  1.69291743e-03 ... -1.01305712e-04\n",
      "    1.91392959e-03 -1.02263270e-03]]\n",
      "\n",
      " [[-6.21630315e-05  5.10329774e-05 -2.28092013e-05 ...  1.07920874e-04\n",
      "    1.30119706e-05 -1.97675195e-06]\n",
      "  [-1.24104583e-04 -2.27344281e-04  1.26052691e-04 ...  1.91734813e-04\n",
      "   -8.30904974e-05 -4.83854990e-07]\n",
      "  [-3.60056205e-04 -4.15128830e-04  3.26851179e-04 ...  5.45707298e-04\n",
      "    1.56098267e-05 -3.03688576e-04]\n",
      "  ...\n",
      "  [-1.18272007e-03 -2.12565227e-03 -2.09544291e-04 ... -4.37521794e-06\n",
      "    1.07703230e-03 -7.92834675e-04]\n",
      "  [-1.36204273e-03 -2.29484052e-03  5.88922121e-05 ... -2.49530189e-04\n",
      "    1.29150692e-03 -7.57328526e-04]\n",
      "  [-1.50786887e-03 -2.41684681e-03  3.82299564e-04 ... -4.69263439e-04\n",
      "    1.51983730e-03 -7.64732249e-04]]\n",
      "\n",
      " [[-6.21630315e-05  5.10329774e-05 -2.28092013e-05 ...  1.07920874e-04\n",
      "    1.30119706e-05 -1.97675195e-06]\n",
      "  [ 1.94991109e-04 -1.03319093e-04 -2.53439619e-04 ...  3.50113900e-04\n",
      "    7.86052042e-05  5.68775031e-05]\n",
      "  [ 4.56453243e-04 -1.20951285e-04 -6.63122570e-04 ...  4.04550781e-04\n",
      "    9.50839894e-05  3.34627985e-04]\n",
      "  ...\n",
      "  [-1.13882509e-03 -1.81677786e-03  1.15825376e-03 ... -5.56661340e-04\n",
      "    1.13844674e-03 -2.88517302e-04]\n",
      "  [-1.31064223e-03 -1.95965148e-03  1.47999485e-03 ... -7.16836774e-04\n",
      "    1.40818162e-03 -5.15099382e-04]\n",
      "  [-1.45075133e-03 -2.06085364e-03  1.78285851e-03 ... -8.48161115e-04\n",
      "    1.65707269e-03 -7.26365717e-04]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-6.21630315e-05  5.10329774e-05 -2.28092013e-05 ...  1.07920874e-04\n",
      "    1.30119706e-05 -1.97675195e-06]\n",
      "  [-1.51006490e-04  7.96250959e-07 -2.13109233e-05 ...  7.18581941e-05\n",
      "   -1.09556007e-04 -2.92530342e-04]\n",
      "  [-1.65174657e-04  3.70604394e-05  7.28386367e-05 ...  6.36179029e-05\n",
      "   -2.33543396e-04 -3.85321473e-04]\n",
      "  ...\n",
      "  [-1.86920271e-03 -1.87309110e-03  1.70774595e-03 ... -2.47744669e-04\n",
      "    1.86931412e-03 -1.39736361e-03]\n",
      "  [-1.95515458e-03 -1.96838309e-03  1.98647589e-03 ... -3.93175171e-04\n",
      "    2.07173964e-03 -1.48985547e-03]\n",
      "  [-2.01574387e-03 -2.03018636e-03  2.23786524e-03 ... -5.22814807e-04\n",
      "    2.24355073e-03 -1.57724542e-03]]\n",
      "\n",
      " [[-6.21630315e-05  5.10329774e-05 -2.28092013e-05 ...  1.07920874e-04\n",
      "    1.30119706e-05 -1.97675195e-06]\n",
      "  [-2.35337298e-04  3.69101035e-05 -2.85216283e-05 ...  1.32016925e-04\n",
      "    2.94716621e-04 -3.17032900e-05]\n",
      "  [-1.14816568e-04  1.01841972e-04  2.46941985e-04 ... -5.38793611e-05\n",
      "    3.31245246e-04 -2.65869930e-05]\n",
      "  ...\n",
      "  [ 6.75717194e-04  2.08742204e-04  1.04590738e-03 ... -6.58148259e-04\n",
      "    8.20880814e-04  1.68956118e-04]\n",
      "  [ 6.64779276e-04  1.65999067e-04  9.92749818e-04 ... -5.99634019e-04\n",
      "    5.83576388e-04  4.81463758e-05]\n",
      "  [ 5.32567152e-04 -1.15941721e-05  9.68616805e-04 ... -5.96667174e-04\n",
      "    4.60702315e-04 -9.36711804e-05]]\n",
      "\n",
      " [[-6.21630315e-05  5.10329774e-05 -2.28092013e-05 ...  1.07920874e-04\n",
      "    1.30119706e-05 -1.97675195e-06]\n",
      "  [-2.30530393e-04  1.02199656e-05  6.28242706e-05 ...  5.43165836e-04\n",
      "    1.44450547e-04 -2.97932362e-04]\n",
      "  [-5.79248772e-05 -2.02286192e-05 -8.45414397e-05 ...  8.80926847e-04\n",
      "    5.90058444e-05 -5.62773668e-04]\n",
      "  ...\n",
      "  [-7.20377895e-04 -1.81221578e-03  1.71596039e-04 ... -4.57752642e-04\n",
      "    6.35106524e-04 -8.19767942e-04]\n",
      "  [-9.70702677e-04 -1.97833637e-03  6.32140669e-04 ... -6.70511567e-04\n",
      "    9.58334771e-04 -8.99377919e-04]\n",
      "  [-1.18225010e-03 -2.09413143e-03  1.07520889e-03 ... -8.40429100e-04\n",
      "    1.27277349e-03 -9.92542016e-04]]], shape=(256, 14, 12001), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset1.take(1): break\n",
    "print(model(src_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "supported-lightning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alive-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer와 loss등은 차차 배웁니다\n",
    "# 혹시 미리 알고 싶다면 아래 문서를 참고하세요\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "# 양이 상당히 많은 편이니 지금 보는 것은 추천하지 않습니다\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-siemens",
   "metadata": {},
   "source": [
    "val_loss를 낮추기 위한 노력\n",
    "\n",
    "- 조기종료(early stopping)은 Neural Network가 과적합을 회피하도록 만드는 정칙화(regularization) 기법 중 하나이다\n",
    "- 훈련 데이터와는 별도로 검증 데이터(validation data)를 준비하고, \n",
    "- 매 epoch 마다 검증 데이터에 대한 오류(validation loss)를 측정하여 모델의 훈련 종료를 제어한다. \n",
    "- 구체적으로, 과적합이 발생하기 전 까지 training loss와 validaion loss 둘다 감소하지만, \n",
    "- 과적합이 일어나면 training loss는 감소하는 반면에 validation loss는 증가한다. \n",
    "- 그래서 early stopping은 validation loss가 증가하는 시점(overfitting이 시작되려는 시점)에서 훈련을 종료한다.\n",
    "- 출처: https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=cjh226&logNo=221468928164 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "under-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "direct-lease",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "445/445 [==============================] - 163s 359ms/step - loss: 3.9027 - accuracy: 0.4744 - val_loss: 2.9786 - val_accuracy: 0.5393\n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 161s 360ms/step - loss: 2.9082 - accuracy: 0.5416 - val_loss: 2.8019 - val_accuracy: 0.5531\n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 161s 361ms/step - loss: 2.7317 - accuracy: 0.5548 - val_loss: 2.6959 - val_accuracy: 0.5611\n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 159s 357ms/step - loss: 2.6022 - accuracy: 0.5633 - val_loss: 2.6218 - val_accuracy: 0.5672\n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 158s 354ms/step - loss: 2.5001 - accuracy: 0.5701 - val_loss: 2.5618 - val_accuracy: 0.5728\n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 159s 356ms/step - loss: 2.4106 - accuracy: 0.5770 - val_loss: 2.5165 - val_accuracy: 0.5779\n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 158s 354ms/step - loss: 2.3232 - accuracy: 0.5847 - val_loss: 2.4730 - val_accuracy: 0.5829\n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 158s 355ms/step - loss: 2.2427 - accuracy: 0.5915 - val_loss: 2.4361 - val_accuracy: 0.5876\n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 160s 359ms/step - loss: 2.1709 - accuracy: 0.5994 - val_loss: 2.4062 - val_accuracy: 0.5931\n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 160s 359ms/step - loss: 2.0978 - accuracy: 0.6078 - val_loss: 2.3812 - val_accuracy: 0.5979\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(dataset1,\n",
    "                          batch_size=32,\n",
    "                          epochs=10,\n",
    "                          validation_data = dataset2,\n",
    "                          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ongoing-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환합니다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 텍스트를 실제로 생성할때는 루프를 돌면서 단어 하나씩 생성해야 합니다. \n",
    "    while True:\n",
    "        predict = model(test_tensor)  # 입력받은 문장의 텐서를 입력합니다. \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   # 우리 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됩니다. \n",
    "\n",
    "        # 우리 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙여 줍니다. \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 우리 모델이 <end>를 예측했거나, max_len에 도달하지 않았다면  while 루프를 또 돌면서 다음 단어를 예측해야 합니다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   # 이것이 최종적으로 모델이 생성한 자연어 문장입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "prime-facility",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , baby <end> '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dimensional-basket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "\n",
    "loss_ax.plot(model_history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(model_history.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-acrobat",
   "metadata": {},
   "source": [
    "## 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-special",
   "metadata": {},
   "source": [
    "- val_loss가 계속 2.3 밑으로는 떨어지지 않아 early stopping 등 조치를 취했지만 2.2 이하로는 떨어지지 않는다.\n",
    "- 다른 방법으로도 계속 시도해보고 있는데 좀 더 방법을 찾아보고 val_loss에 대한 업데이트가 필요하다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
