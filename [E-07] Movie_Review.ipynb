{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mobile-knight",
   "metadata": {},
   "source": [
    "# 간단한 예제로 접근하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "empirical-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-talent",
   "metadata": {},
   "source": [
    "#### 사전을 만들기 위해 모든 문장을 단어 단위로 쪼갠 후에 파이썬 딕셔너리(dict) 자료구조로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "flying-input",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-cartoon",
   "metadata": {},
   "source": [
    "#### 텍스트 데이터를 숫자로 바꾸기, {텍스트:인덱스} 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "verified-consent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "provincial-token",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "automated-indonesian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "attended-lewis",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "recorded-rescue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "individual-sacrifice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i feel hungry', 'i eat lunch', 'now i feel happy']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "nuclear-steel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "roman-leeds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "alien-reviewer",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "thick-apparel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-190c1be7d3f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mraw_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_encoded_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m     if any(isinstance(x, (\n\u001b[1;32m    959\u001b[0m         np_arrays.ndarray, np.ndarray, float, int)) for x in input_list):\n\u001b[0;32m--> 960\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_convert_numpy_or_python_types\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3307\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3308\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3309\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3310\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1403\u001b[0m   \"\"\"\n\u001b[1;32m   1404\u001b[0m   return convert_to_tensor_v2(\n\u001b[0;32m-> 1405\u001b[0;31m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0m\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1413\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-porter",
   "metadata": {},
   "source": [
    "- Embedding 레이어의 인풋이 되는 문장 벡터는 그 길이가 <b>일정</b>해야 한다!!\n",
    "- Tensorflow에서는 keras.preprocessing.sequence.pad_sequences라는 편리한 함수를 통해 문장 벡터 뒤에 패딩(\\<PAD>\\)을 추가하여 \\\n",
    "    길이를 일정하게 맞춰주는 기능을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "elder-throat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-alignment",
   "metadata": {},
   "source": [
    "- 짧은 문장 뒤쪽이 0으로 채워짐. \\<PAD> 가 0에 맵핑되어 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ordered-lithuania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.00296147 -0.03568434 -0.0111909   0.04628226]\n",
      "  [-0.02697146 -0.02013736 -0.02535086  0.02639626]\n",
      "  [ 0.02068118  0.04281309  0.03915552  0.0059217 ]\n",
      "  [ 0.03279478  0.04243739  0.01768359 -0.01237042]\n",
      "  [ 0.02514518  0.0178332  -0.03707708 -0.02581676]]\n",
      "\n",
      " [[ 0.00296147 -0.03568434 -0.0111909   0.04628226]\n",
      "  [-0.02697146 -0.02013736 -0.02535086  0.02639626]\n",
      "  [ 0.03939413  0.01944068 -0.03867608 -0.03335252]\n",
      "  [ 0.00835542 -0.04282219 -0.04460794  0.03234562]\n",
      "  [ 0.02514518  0.0178332  -0.03707708 -0.02581676]]\n",
      "\n",
      " [[ 0.00296147 -0.03568434 -0.0111909   0.04628226]\n",
      "  [-0.00653962 -0.00254332 -0.00235833 -0.01715804]\n",
      "  [-0.02697146 -0.02013736 -0.02535086  0.02639626]\n",
      "  [ 0.02068118  0.04281309  0.03915552  0.0059217 ]\n",
      "  [-0.04419969  0.03369445  0.01860652  0.0327617 ]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-sacrifice",
   "metadata": {},
   "source": [
    "-  output의 shape=(3, 5, 4)에서 3, 5, 4의 의미\n",
    "    - 3은 입력문장 개수, 5는 입력문장의 최대 길이, 4는 워드 벡터의 차원 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-medicine",
   "metadata": {},
   "source": [
    "RNN은 시간의 흐름에 따라 새롭게 들어오는 입력에 따라 변하는 현재 상태를 묘사하는 state machine으로 설계되었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "vocational-geology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-richards",
   "metadata": {},
   "source": [
    "#### 문장 전체를 한꺼번에 한 방향으로 길이 7짜리 필터로 스캐닝 하면서 7단어 이내에서 발견되는 특징을 추출하여 그것으로 문장을 분류하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "chinese-table",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-endorsement",
   "metadata": {},
   "source": [
    "#### 전체 문장 중에서 단 하나의 가장 중요한 단어만 피처로 추출하여 그것으로 문장의 긍정/부정을 평가하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "equipped-nursery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-township",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
